#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon May  5 09:47:56 2025

@author: annabel_large


ABOUT:
======
6th test for substitution models

test the independent site class code by scoring manually with a loop

"""
import jax
import numpy as np

import numpy.testing as npt
import unittest

from tests.data_processing import (str_aligns_to_tensor,
                                   summarize_alignment)

from models.simple_site_class_predict.model_functions import (rate_matrix_from_exch_equl,
                                                              cond_logprob_emit_at_match_per_mixture,
                                                              joint_logprob_emit_at_match_per_mixture,
                                                              lse_over_match_logprobs_per_mixture,
                                                              joint_prob_from_counts)




THRESHOLD = 1e-6


class TestAlignmentLoglikeGTRMixture(unittest.TestCase):
    """
    SUBSTITUTION PROCESS SCORING TEST 6
    
    B: batch (samples)
    L: length (number of alignment columns)
    C: hidden site classes
    K: rate multipliers
    T: branch lengths (time)
    A: alphabet
    
    About
    ------
    Check the log-probability of some fake alignments by hand loops, and with
      my functions; using scoring matrices generated by validated functions;
      under assumption of independent site class mixtures
    
    """
    def test_score_alignment(self):
        ### generate fake alignments
        fake_aligns = [ ('AC-A','D-ED'),
                        ('D-ED','AC-A'),
                        ('ECDAD','-C-A-'),
                        ('-C-A-','ECDAD') ]
        
        fake_aligns =  str_aligns_to_tensor(fake_aligns) #(B,L,3)
            
        vmapped_summarize_alignment = jax.vmap(summarize_alignment, 
                                               in_axes=0, 
                                               out_axes=0)
        counts =  vmapped_summarize_alignment( fake_aligns )
        match_counts = counts['match_counts'][:, :4, :4] #(B,A,A)
                
        
        ### params to work with
        exchangeabilities = np.array([[0, 1, 2, 3],
                                      [1, 0, 4, 5],
                                      [2, 4, 0, 6],
                                      [3, 5, 6, 0]]) #(A,A)
        
        equilibrium_distributions_1 = np.array([0.1, 0.2, 0.3, 0.4])
        equilibrium_distributions_2 = np.array([0.4, 0.3, 0.2, 0.1])
        equilibrium_distributions = np.stack([equilibrium_distributions_1,
                                              equilibrium_distributions_2]) #(C,A)
        del equilibrium_distributions_1, equilibrium_distributions_2
        
        raw_Q = rate_matrix_from_exch_equl(exchangeabilities,
                                           equilibrium_distributions,
                                           norm=True) #(C,A,A)
        
        rate_mults = np.array( [[  1,   2,   3,   4],
                                [0.1, 0.2, 0.3, 0.4]] ) #(C, K)
        Q = np.multiply( raw_Q[:,None,...], rate_mults[...,None, None] ) #(C, K, A, A)
        
        class_probs = np.array([0.4, 0.6]) #(C)
        rate_mult_probs = np.array( [[0.25, 0.25, 0.25, 0.25],
                                     [0.1,  0.2,  0.3,  0.4]] ) #(C,K)
        
        log_class_probs = np.log(class_probs) #(C)
        log_rate_mult_probs = np.log(rate_mult_probs) #(C,K)
        
        P_emit = 0.995
        t_array = np.array( [0.3, 1.0, 0.2] ) #(T)
        
        
        B = fake_aligns.shape[0]
        L = fake_aligns.shape[1]
        C = Q.shape[0]
        K = rate_mult_probs.shape[1]
        T = t_array.shape[0]
        A = Q.shape[1]
        
        log_cond = cond_logprob_emit_at_match_per_mixture(t_array = t_array,
                                                              scaled_rate_mat_per_mixture = Q) #(T,C,A,A)
        log_joint = joint_logprob_emit_at_match_per_mixture(cond_logprob_emit_at_match_per_mixture = log_cond,
                                                              log_equl_dist_per_mixture = np.log(equilibrium_distributions)) #(T,C,A,A)
        del Q, log_cond
        
        ### manually score each site
        true_scores = np.zeros( (T,B) ) #(T,B)
        for t in range(T):
            for b in range(B):
                for l in range(L):
                    anc_tok, desc_tok, alignment_tok = fake_aligns[b, l, :]
                    if alignment_tok == 1:
                        prob_of_this_column = 0
                        for c in range(C):
                            for k in range(K):
                                mixture_joint_matrix = np.exp(log_joint[t,c,k,...])
                                mixture_prob = class_probs[c] * rate_mult_probs[c,k]
                                
                                # P(c) P(x,y|c,t)
                                prob_of_this_column += (mixture_prob *
                                                       mixture_joint_matrix[anc_tok-3, desc_tok-3] )
                        
                        # scale final emission score by P(emit)
                        prob_of_this_column = prob_of_this_column * P_emit
                        true_scores[t,b] += np.log(prob_of_this_column)
        
        # finally, probability of ending the sequence
        true_scores = true_scores + np.log(1-P_emit)
        
        
        ### calculate with my function
        pred_scoring_matrix = lse_over_match_logprobs_per_mixture(log_class_probs = log_class_probs,
                                                                  log_rate_mult_probs = log_rate_mult_probs,
                                                                  logprob_emit_at_match_per_mixture = log_joint) #(T,A,A)
        
        fake_batch = (match_counts, 
                      np.zeros((B,A)),
                      np.zeros((B,A)),
                      np.zeros((B, 4, 4)))
        
        # do this one timepoint at a time, to avoid logsumexp
        pred_scores = []        
        for t_idx in range(T):
            t = t_array[t_idx][None]
            scoring_matrices_dict = {'joint_logprob_emit_at_match': pred_scoring_matrix[t_idx,...][None,...],
                                     'all_transit_matrices': 
                                         {'joint': np.log(np.array([P_emit, 1 - P_emit]))
                                          } 
                                    }
            
            out = joint_prob_from_counts( batch = fake_batch,
                                          times_from = 'geometric',
                                          score_indels = False,
                                          scoring_matrices_dict = scoring_matrices_dict,
                                          t_array = t,
                                          exponential_dist_param = None,
                                          norm_loss_by = None )
        
            pred_scores.append( -out['joint_neg_logP'] )
            
        npt.assert_allclose(true_scores, pred_scores, atol=THRESHOLD)

if __name__ == '__main__':
    unittest.main()
