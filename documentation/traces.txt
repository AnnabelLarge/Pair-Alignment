counts-based trace (training):
==============================

rename/remove these:
---------------------
                  all_counts   ->   batch
                     t_array   ->   (REMOVE; provided in batch)
                     pairHMM   ->   all_model_instances
 (params_dict, hparams_dict)   ->   all_trainstates
             training_rngkey   ->   training_rngkey (same)
     loss_type='conditional'   ->   loss_type (same, but remove default)
     norm_loss_by='desc_len'   ->   norm_loss_by (same, but remove default)
           DEBUG_FLAG=False)   ->   (REMOVE)

add these:
----------
interms_for_tboard
num_site_classes (set to 1 for now; expand to independent sums over substitution site classes later)


NEW trace:
----------
@ = parted at beginning

batch
training_rngkey
all_trainstates
max_seq_len = None
max_align_len = None
@ all_model_instances
@ norm_loss_by
@ interms_for_tboard 
@ more_attributes (place in separate, persistent dictionary)
   > loss_type 
   > num_site_classes
   > exponential_dist_param

(plus **kwargs)



full alignment + seq embedders trace (training):
=================================================

remove these:
-------------
which_alignment_states_to_encode


add these:
----------
loss_type


NEW trace:
----------
@ = parted at beginning

batch
training_rngkey
all_trainstates
max_seq_len = None
max_align_len = None
@ all_model_instances
@ norm_loss_by
@ interms_for_tboard 
@ more_attributes (place in separate, persistent dictionary)
   > concat_fn
   > (ff) add_prev_alignment_info
   > (neuralHMM) loss_type 
   > (neuralHMM) exponential_dist_param


WITH JAX.LAX.SCAN 
full alignment + seq embedders trace (training):
=================================================

remove these:
-------------
which_alignment_states_to_encode
have_time_values (if possible?)


add these:
----------
loss_type


NEW trace:
----------
@ = parted at beginning

batch
training_rngkey
all_trainstates
max_seq_len = None
max_align_len = None
@ all_model_instances
@ norm_loss_by
@ interms_for_tboard 
@ more_attributes (place in separate, persistent dictionary)
   > (scan implementations only) length_for_scan
   > concat_fn
   > loss_type 
   > (ff) add_prev_alignment_info
   > (neuralHMM) loss_type 
   > (neuralHMM) exponential_dist_param


edits to eval functions:
========================
- remove extra_args_for_eval; only used this to have the option of saving transformer attention maps... which I never do
- won't have training_rngkey (obviously)



(FUTURE) markovian site classes trace (training):
=================================================
@ = parted at beginning

batch
training_rngkey
all_trainstates
max_seq_len = None
max_align_len = None
@ all_model_instances
@ norm_loss_by 
@ interms_for_tboard 
@ more_attributes (place in separate, persistent dictionary)
   > loss_type 
   > num_site_classes
